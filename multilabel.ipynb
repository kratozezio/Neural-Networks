{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple, Dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiLabelClassifier:\n",
    "\n",
    "#     def __init__(self, X, Y, layer_dims, n_iterations = 100, learning_rate = 0.1, print_cost = False, draw_cost = False):\n",
    "#         self.X = X\n",
    "#         self.Y = Y\n",
    "#         self.layer_dims = layer_dims\n",
    "#         self.n_iterations = n_iterations\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.print_cost = print_cost\n",
    "#         self.draw_cost = draw_cost\n",
    "#         self.n_layers = len(layer_dims)\n",
    "#         self.params = {}\n",
    "#         self.grads = {}\n",
    "    \n",
    "#     def initialize_params(self) -> Dict:\n",
    "#         ''' \n",
    "#         Initiazlize the NN according to layer dimensions\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         parameters: ``Dict``\n",
    "#             Dictionary containing values for weights and biases for all connections\n",
    "#         '''\n",
    "#         for l in range(1, self.n_layers):\n",
    "#             self.params[f'w{l}'] = torch.rand((self.layer_dims[l], self.layer_dims[l-1])) * 0.01\n",
    "#             self.params[f'b{l}'] = torch.zeros(self.layer_dims[l])\n",
    "       \n",
    "\n",
    "#     def forward_prop(self, AL):\n",
    "#         '''\n",
    "#         Carry out forward propagation for one metaing sample\n",
    "#         '''\n",
    "\n",
    "#         w = self.param['w']\n",
    "#         z = torch.mm(AL, w) + b\n",
    "#         return z\n",
    "         \n",
    "\n",
    "#     def backward_prop():\n",
    "#         '''\n",
    "#         Carry out backward propagation for one metaing sample\n",
    "#         '''\n",
    "#         pass\n",
    "\n",
    "#     def split_data(self, test_size=0.2):\n",
    "#         return train_test_split(self.X, self.Y, test_size)\n",
    "\n",
    "#     def meta():\n",
    "#         '''\n",
    "#         meta the model by carrying out forward and backward propagation for all metaing samples\n",
    "#         '''\n",
    "#         pass\n",
    "\n",
    "#     def predict():\n",
    "#         '''\n",
    "#         Make a prediction for given input data\n",
    "#         '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../../datasets/MovieSummaries/movie.metadata.tsv\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.columns = [\"movie_id\", 1, 2, 3, 4, 5, 6, 7, \"genre\"]\n",
    "meta = meta[['movie_id', 'genre']]\n",
    "meta['movie_id'] = meta['movie_id'].astype(str)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "plots = []\n",
    "movie_ids = []\n",
    "\n",
    "with open(\"../../datasets/MovieSummaries/plot_summaries.txt\", 'r') as f:\n",
    "    reader = csv.reader(f, dialect='excel-tab')\n",
    "    for row in reader:\n",
    "        rows.append(row)    \n",
    "\n",
    "for i in rows:\n",
    "    movie_ids.append(i[0])\n",
    "    plots.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.DataFrame({\"movie_id\": movie_ids, \"plot\": plots})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.merge(movies, meta, on=\"movie_id\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_genres = []\n",
    "for i in movies['genre']:\n",
    "    cleaned_genres.append(list(json.loads(i).values()))\n",
    "\n",
    "movies['cleaned_genre'] = cleaned_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[(movies['cleaned_genre'].str.len() != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop('genre', axis=1)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = []\n",
    "genre_freq = {}\n",
    "\n",
    "for row in movies['cleaned_genre']:\n",
    "    for genre in row:\n",
    "        if genre not in all_genres:\n",
    "            all_genres.append(genre)\n",
    "            genre_freq[genre] = 1\n",
    "        else:\n",
    "            genre_freq[genre] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genres = dict(sorted(genre_freq.items(), key = lambda x: x[1], reverse=True)[:10])\n",
    "top_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(18, 10), dpi=50)\n",
    "plt.title(\"Most Frequent Genres\")\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.bar(top_genres.keys(), top_genres.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"<br />\", \" \")  # Remove html\n",
    "    text = text.translate(str.maketrans(string.punctuation, \" \"*len(string.punctuation)))  # Remove punctuations\n",
    "    text = re.sub(r\"\\d\", \"\", text)\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    stopwords_english = stopwords.words(\"English\")\n",
    "    for word in words:\n",
    "        if word in stopwords_english:\n",
    "            text = re.sub(r\"\\b%s\\b\" % word, \"\", text)\n",
    "\n",
    "    text = re.sub(' +', ' ', text) # Remove extra spaces\n",
    "    # text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before cleanup: \", movies['plot'][0])\n",
    "movies['plot'] = movies['plot'].map(preprocess)\n",
    "print(\"After cleanup: \", movies['plot'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(df):\n",
    "    \n",
    "    vocab = {}\n",
    "    stopwords_english = stopwords.words(\"English\")\n",
    "    for plot in df.values:\n",
    "        words = word_tokenize(plot)\n",
    "        for word in words:\n",
    "            if word not in stopwords_english: \n",
    "                if word not in vocab:\n",
    "                    vocab[word] = 1\n",
    "                else:\n",
    "                    vocab[word] += 1\n",
    "\n",
    "    return vocab  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = create_vocab(movies['plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = dict(sorted(vocab.items(), key = lambda x: x[1], reverse=True)[:10])\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(top_words.keys(), top_words.values())\n",
    "plt.title(\"Most Frequent Words\")\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = iterative_train_test_split(movies, test_size = 0.2)\n",
    "train=movies.sample(frac=0.7)\n",
    "test=movies.drop(train.index)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = []\n",
    "genre_freq = {}\n",
    "\n",
    "for row in train['cleaned_genre']:\n",
    "    for genre in row:\n",
    "        if genre not in all_genres:\n",
    "            all_genres.append(genre)\n",
    "            genre_freq[genre] = 1\n",
    "        else:\n",
    "            genre_freq[genre] += 1\n",
    "\n",
    "len(all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = MultiLabelBinarizer()\n",
    "train_y = mb.fit_transform(train['cleaned_genre']) \n",
    "train_y = torch.tensor(train_y)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=10000) \n",
    "tfidf.fit(train['plot'])\n",
    "train_x = tfidf.transform(train['plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape, train_y.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_train = train_x.tocoo()\n",
    "values = coo_train.data\n",
    "indices = np.vstack((coo_train.row, coo_train.col))\n",
    "i = torch.LongTensor(indices)\n",
    "v = torch.FloatTensor(values)\n",
    "shape = coo_train.shape\n",
    "\n",
    "train_x = torch.sparse.FloatTensor(i, v, torch.Size(shape)).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['plot'].shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "   params ={}\n",
    "   \n",
    "   for l in range(1, len(layer_dims)):\n",
    "      params[f'W{l}'] = torch.rand(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "      params[f'b{l}'] = torch.zeros((layer_dims[l], 1))\n",
    "\n",
    "   return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W, b):\n",
    "\n",
    "    Z = torch.mm(W, A_prev) + b\n",
    "    cache = (A_prev, W, b)\n",
    "\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = torch.sigmoid(Z), Z\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = torch.relu(Z), Z\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, params):\n",
    "\n",
    "    caches = []\n",
    "    L = len(params) // 2\n",
    "    A_prev = X\n",
    "    for l in range(1, L):\n",
    "        A, cache = linear_activation_forward(A_prev, params[f'W{l}'], params[f'b{l}'], \"relu\")\n",
    "        caches.append(cache)\n",
    "        A_prev = A\n",
    "\n",
    "    AL, cache = linear_activation_forward(A_prev, params[f'W{L}'], params[f'b{L}'], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "\n",
    "    m = Y.shape[1]\n",
    "    cost = - torch.mean(((Y * torch.log(AL).transpose(0, 1)) + ((1 - Y) * torch.log(1 - AL).transpose(0, 1))))\n",
    "    \n",
    "    return torch.squeeze(cost)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dz, cache):\n",
    "\n",
    "    A_prev, w, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dw = torch.mm(dz, A_prev.transpose(0, 1)) / m\n",
    "    db = torch.sum(dz, axis=1, keepdims=True) / m\n",
    "    dA_prev = torch.mm(w.transpose(0, 1), dz)\n",
    "\n",
    "    return dA_prev, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "\n",
    "    Z = cache\n",
    "    s = 1 / (1 + torch.exp(-Z))\n",
    "    dz = dA.transpose(0, 1) * s * (1 - s)\n",
    "\n",
    "    return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "\n",
    "    Z = cache\n",
    "    dz = dA\n",
    "    dz[Z <= 0] = 0\n",
    "\n",
    "    return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    if activation == 'relu':\n",
    "        dz = relu_backward(dA, activation_cache)\n",
    "\n",
    "    elif activation == 'sigmoid':\n",
    "        dz = sigmoid_backward(dA, activation_cache)\n",
    "\n",
    "    dA_prev, dw, db = linear_backward(dz, linear_cache)\n",
    "\n",
    "    return dA_prev, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "\n",
    "    L = len(caches)\n",
    "    m = Y.shape[1]\n",
    "    grads = {}\n",
    "\n",
    "    dAL = -(torch.div(Y, AL.transpose(0, 1)) - torch.div(1 - Y, 1 - AL.transpose(0, 1)))\n",
    "\n",
    "    grads[f'dA{L-1}'], grads[f'dW{L}'], grads[f'db{L}'] = linear_activation_backward(dAL, caches[L-1], \"sigmoid\")\n",
    "    for l in reversed(range(L-1)):\n",
    "        dA_prev, dw, db = linear_activation_backward(grads[f'dA{l+1}'], caches[l], \"relu\")\n",
    "        grads[f'dW{l+1}'] = dw\n",
    "        grads[f'db{l+1}'] = db\n",
    "        grads[f'dA{l}']  = dA_prev  \n",
    "        \n",
    "    return grads  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(params, grads, learning_rate):\n",
    "\n",
    "    L = len(params) // 2\n",
    "    for l in range(1, L+1):\n",
    "        params[f'W{l}'] -= learning_rate * grads[f'dW{l}']\n",
    "        params[f'b{l}'] -= learning_rate * grads[f'db{l}']\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, parameters):\n",
    "\n",
    "    AL, caches = L_model_forward(X_test, parameters)\n",
    "    \n",
    "    AL[AL < 0.5] = int(0)\n",
    "    AL[AL >= 0.5] = int(1)\n",
    "    \n",
    "    return torch.squeeze(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.5, num_iterations = 10, print_cost=False):\n",
    "    costs = []                \n",
    "\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        cost = compute_cost(AL, Y)\n",
    "        costs.append(cost)\n",
    "  \n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "     \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        if print_cost and i % 10 == 0:\n",
    "            print (f\"Cost after iteration {i}: {cost}\")\n",
    "       \n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.plot(range(1, num_iterations + 1), costs)\n",
    "    plt.xlabel(\"No. of iterations\")\n",
    "    plt.ylabel(\"Cost Function\")\n",
    "    plt.show()\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = L_layer_model(train_x.transpose(0, 1), train_y, [10000, 10, train_y.shape[1]], num_iterations=100, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = tfidf.transform(test['plot'])\n",
    "\n",
    "coo_test = test_x.tocoo()\n",
    "values = coo_test.data\n",
    "indices = np.vstack((coo_test.row, coo_test.col))\n",
    "i = torch.LongTensor(indices)\n",
    "v = torch.FloatTensor(values)\n",
    "shape = coo_test.shape\n",
    "\n",
    "test_x = torch.sparse.FloatTensor(i, v, torch.Size(shape)).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
